{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torch.nn import Sequential, Conv1d, MaxPool1d, Flatten, Linear,ReLU,Softmax,Tanh\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, label_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.path = os.path.join(self.root_dir, self.label_dir)\n",
    "        self.data_path = os.listdir(self.path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        txt_name = self.data_path[idx]\n",
    "        data_item_path = os.path.join(self.root_dir, self.label_dir, txt_name)\n",
    "        data = numpy.loadtxt(data_item_path)\n",
    "        \n",
    "        #list = []\n",
    "        #data = list.append(data)\n",
    "        \n",
    "        label = self.label_dir\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.model1 = Sequential(\n",
    "            Conv1d(1, 16, kernel_size=11),\n",
    "            Conv1d(16, 16, kernel_size=3),\n",
    "            Conv1d(16, 16, kernel_size=3),\n",
    "            MaxPool1d(3),\n",
    "            Conv1d(16, 64, kernel_size=3),\n",
    "            Conv1d(64, 64,kernel_size=3),\n",
    "            MaxPool1d(3),\n",
    "            Conv1d(64, 64,kernel_size=3),\n",
    "            Conv1d(64, 64,kernel_size=3),\n",
    "            MaxPool1d(3),\n",
    "            Flatten(),\n",
    "            Linear(448, 64),\n",
    "            Linear(64, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'E:\\\\1D-Data\\\\train\\\\'\n",
    "test_data_dir = 'E:\\\\1D-Data\\\\val\\\\'\n",
    "bus_label_dir = '0'\n",
    "car_label_dir = '1'\n",
    "man_label_dir = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ddac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bus_data = MyData(train_data_dir,bus_label_dir)\n",
    "train_car_data = MyData(train_data_dir,car_label_dir)\n",
    "train_man_data = MyData(train_data_dir,man_label_dir)\n",
    "train_data = train_bus_data+train_car_data+train_man_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b73f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bus_data = MyData(test_data_dir,bus_label_dir)\n",
    "test_car_data = MyData(test_data_dir,car_label_dir)\n",
    "test_man_data = MyData(test_data_dir,man_label_dir)\n",
    "test_data = test_bus_data+test_car_data+test_man_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed634090",
   "metadata": {},
   "outputs": [],
   "source": [
    "BatchSize = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ea796",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_loader_train = torch.utils.data.DataLoader(train_data, batch_size=BatchSize, shuffle=True)  # 训练集\n",
    "Data_loader_test = torch.utils.data.DataLoader(test_data, batch_size=BatchSize, shuffle=True)  # 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078807f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据集长度\n",
    "dataset_train_size = len(Data_loader_train)\n",
    "dataset_test_size = len(Data_loader_test)\n",
    "print(\"训练数据集长度：{}\".format(dataset_train_size))\n",
    "print(\"测试数据集长度：{}\".format(dataset_test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c830b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "OneD_nn = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b561c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器\n",
    "learn_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(OneD_nn.parameters(), lr=learn_rate)\n",
    "\n",
    "# 设置训练网络参数\n",
    "# 记录训练次数\n",
    "total_train_step = 0\n",
    "# 记录测试次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 30\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"log\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"----第 {} 轮训练开始----\".format(i + 1))\n",
    "\n",
    "    # 训练步骤开始\n",
    "    OneD_nn.train()  # 有dropout和normlizer层需要调用\n",
    "    for data in Data_loader_train:\n",
    "        datas, targets = data\n",
    "        empty_list_1 = []\n",
    "        for i in range(BatchSize):\n",
    "            #print(data_1[i].size())\n",
    "            #print(data_1[i])\n",
    "            b = datas[i].numpy()\n",
    "            b=[b.tolist()]\n",
    "            empty_list_1.append(b)\n",
    "        empty_list_1 =torch.Tensor(empty_list_1)\n",
    "        \n",
    "        list = []\n",
    "        for i in range(BatchSize):\n",
    "            list.append(int(targets[i]))\n",
    "        list = torch.LongTensor(list)  \n",
    "        \n",
    "        '''\n",
    "        if targets == ('bus',):\n",
    "            targets = [0]\n",
    "        elif targets == ('car',):\n",
    "            targets = [1]\n",
    "        elif targets == ('man',):\n",
    "            targets = [2] \n",
    "        '''\n",
    "        #targets = torch.LongTensor(targets)\n",
    "        #print(datas)\n",
    "        output_x = OneD_nn(empty_list_1)\n",
    "        #print(targets)\n",
    "        #print(output_x)\n",
    "        loss_x = loss(output_x, list)\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()  # 梯度清0\n",
    "        loss_x.backward()  # 求解grad梯度\n",
    "        optimizer.step()  # 更新weight\n",
    "\n",
    "        total_train_step = total_train_step + 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数：{}，Loss：{} \".format(total_train_step, loss_x.item()))\n",
    "            writer.add_scalar(\"train_loss\", loss_x.item(), total_train_step)\n",
    "\n",
    "    # 测试步骤开始\n",
    "    OneD_nn.eval()  # 同理\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data in Data_loader_test:\n",
    "            datas, targets = data\n",
    "            \n",
    "            empty_list_2 = []\n",
    "            for i in range(BatchSize):\n",
    "                #print(data_1[i].size())\n",
    "                #print(data_1[i])\n",
    "                b = datas[i].numpy()\n",
    "                b=[b.tolist()]\n",
    "                empty_list_2.append(b)\n",
    "            empty_list_2 =torch.Tensor(empty_list_2)\n",
    "            \n",
    "            list = []\n",
    "            for i in range(BatchSize):\n",
    "                list.append(int(targets[i]))\n",
    "            list = torch.LongTensor(list) \n",
    "            '''\n",
    "            if targets == ('bus',):\n",
    "                targets = [0]\n",
    "            elif targets == ('car',):\n",
    "                targets = [1]\n",
    "            elif targets == ('man',):\n",
    "                targets = [2] \n",
    "            ''' \n",
    "            #targets = torch.LongTensor(targets)\n",
    "            \n",
    "            output_x = OneD_nn(empty_list_2)\n",
    "            loss_x = loss(output_x, list)\n",
    "            total_test_loss = total_test_loss + loss_x.item()\n",
    "            accuracy = (output_x.argmax(1) == list).sum()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "    print(\"整体测试集上的loss：{}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率：{}\".format(total_accuracy / dataset_test_size))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    writer.add_scalar(\"test_accuracy\", total_accuracy / dataset_test_size, total_test_step)\n",
    "    total_test_step = total_test_step + 1\n",
    "    if i == epoch-1:\n",
    "        torch.save(OneD_nn, \"OneD_nn_{}.pth\".format(i))\n",
    "    # torch.save(xjl_nn.state_dict(),\"xjl_nn_{}.pth\".format(i))\n",
    "    print(\"模型已保存\")\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab372a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
